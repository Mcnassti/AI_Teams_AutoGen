{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Professional Can Agentic AI Teams Get?\n",
    "\n",
    "by [Oliver Morris](https://linkedin.com/in/olimoz)\n",
    "26 November 2023\n",
    "\n",
    "ChatGPT was released on 30 November 2022, just under a year ago. Then, over the summer of 2023, a number of packages were released for creating software development teams from agents based on LLMs:\n",
    "- [ChatDev](https://github.com/OpenBMB/ChatDev)\n",
    "- [MetaGPT](https://github.com/geekan/MetaGPT)\n",
    "- [AutoGen](https://github.com/microsoft/autogen)\n",
    "\n",
    "In October I reviewed the subject of agentic teams and compared these three packages:\n",
    "- [Can AI Team Up with Itself for Our Benefit?](https://medium.com/@olimoz/the-collaboration-code-from-ai-solo-act-to-symphony-303d975832fe)\n",
    "- [Which AI Team Framework Hustles Hardest?](https://medium.com/@olimoz/teams-of-ai-coders-hustle-in-a-hackathon-148683cb9c65?)\n",
    "\n",
    "The articles presented agentic AI teams with a data science challenge, but decomposed it into a digestible sequence of steps. Arriving at those steps was more than half the work, it could be argued that the teams were engaging in relatively trivial tasks. Nonetheless, within these limits ChatDev won the comparison, largely because it was most effective with GPT3.5. AutoGen was limited by dependency on GPT4 and its 8k context window. \n",
    "\n",
    "Then, on Nov 6th, OpenAI released GPT4 Turbo with a 128k context window. This allows far greater complexity in the tasks we can tackle with agentic AI teams. This article returns to the original data science challenge but give AutoGen no clues on how to solve it. We're going to see how professional the automated team's solution can be.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Professional Can AutoGen Teams Be?\n",
    "\n",
    "Unleashed form the context window, I initally let the agents rush into the open fields of data exploration. This imposed substantial API charges from OpenAI and delivered little benefit.\n",
    "Two behaviours become apparent when trying to use agentic teams for coding:\n",
    "\n",
    "**1. Agent's desire to oblige* leads to rushed code**\n",
    "Agile data science is iterative, repeatedly combing over data and algorithms in order to incrementally pinpoint the optimal solution.\n",
    "One might assume that asking the team to deconstruct the problem into steps would foster a more considered approach. But no. An agent charged with planning will delineate the steps required, but other agents over eagerly attempt too many of those steps in one leap. \n",
    "\n",
    "*In AutoGen, GPT3.5 is so obliging that it can easily enter a 'gratitude loop' where teams members thank each other rather than progressing with work!*\n",
    "\n",
    "**2. Agents are not human, each agent has depth over many fields of expertise**\n",
    "Taking inspiration from our human experience, it is tempting to configure a team with many agents, each with a specialised role. If using GPT4, or any other generalised model, then regardless of their assigned role, all the agents remain deeply knowledgeable in many fields. They all know each other's job, ever been to a meeting like that? Soon gets confusing.\n",
    "Our challenge as the PM of super human developers is to put these abilities to work constructively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Small Teams Engaging in Deeply Iterative Work\n",
    "\n",
    "After much experimentation, the optimal team for this data science project was:\n",
    "\n",
    "1. Data scientist who proposes code, but does not execute it\n",
    "2. Critic who critiques all proposed code and plans\n",
    "3. Executor (a local python environment) who executes code and reports the result or errors\n",
    "4. Admin (a human in the loop to approve a plan and terminate the project, no other input)\n",
    "\n",
    "Other common team members were initially included, but found to add little value:\n",
    "- Sofware Engineer (separate from Data scientist)\n",
    "- Planner\n",
    "- Business Analyst\n",
    "- Agile Project Manager / Scrum Master\n",
    "\n",
    "We need to relearn our intuitions, this is not a human team. In effect, we are simply trying to get GPT4 to prompt itself as effectively as possible. Every team member is already a capable coder, a well trained business analyst, etc. Two team members can prompt each other well. A Data Scientist's proposals can be challenged a critic. But there may be more intelligent approaches, perhaps a critic proficient in selecting which of the many prompting techniques to apply.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Challenge\n",
    "\n",
    "Verbatim as presented to the teams:\n",
    "\n",
    "\"\"\"\n",
    "KICK OFF NOTES\n",
    "\n",
    "The source data is at: '/home/oliver/Documents/LangChain/ProductDevelopment/AutoGen/Data/data.xlsx' \n",
    "This is a list of applications which use AI. The client wants to understand and characterise the market, what sectors are likely to be over served and which are underserved.\n",
    "The client needs a summary diagram or table which can comfortably fit on one page of A4.\n",
    "\n",
    "The client is keen that :\n",
    "(a) no preconceptions are imposed on the data, select algorithms which avoid unevidenced assumptions\n",
    "(b) algorithm hyperparameters are optimised\n",
    "\"\"\"\n",
    "\n",
    "## Explanation\n",
    "\n",
    "The data in the challenge is a spreadsheet of AI tools available in October 2023. Each row has the tool name, a description of its use case and a measure of its popularity.\n",
    "The source for the data is theresanaiforthat.com\n",
    "\n",
    "The above challenge was first completed manually, with occasional help from ChatGPT, resulting in the notebook at:\n",
    "https://github.com/olimoz/AI_Teams/blob/main/Clustering_AI_tools_WithGPT4AA.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prompting Matters\n",
    "\n",
    "As a developer I want to spend my time coding software, but in truth, the detail of the prompts are crucial to quality output from LLM's\n",
    "\n",
    "Two approaches are considered. \n",
    "Firstly, the team is presented the challenge and expected to complete it in one task:\n",
    "\n",
    "- The team is instructed to code iteratively, as for a Jupyter Notebook. \n",
    "    - Jupyter notebooks enforce the pattern of coding small chunks, viewing results and reacting accordingly.\n",
    "    - Of course, they don't have a Notebook, they only believe they do. It is actually a simple python environment\n",
    "    - Work has begun on an Executor who is a real Jupyter Notebook, but this is not at all trivial\n",
    "- The Data Scientist and Critic are instructed to work in a loop:\n",
    "    - Data scientist to propose an approach to the problem or code\n",
    "    - Critic to offer suggestions for improvements\n",
    "    - Data Scientist to enhance output accordingly, but proceed without more critique (for fear of an infinite loop forming)\n",
    "    - Data Scientist to react to code errors\n",
    "    - Proceed to next problem (Notebook cell) and repeat the loop\n",
    "\n",
    "Secondly the team is prompted as above, but given a separate task per phase of the [Microsoft Team Data Science Process](https://learn.microsoft.com/en-us/azure/architecture/data-science-process/overview)\n",
    "\n",
    "- Each phase's prompt is prefixed with a detailed phase description, as inspired by Microsoft TDSP. \n",
    "- Only one project phase prompted at a time\n",
    "    - in AutoGen we execute this as a series of 'groupchats'\n",
    "- The end of each phase is shutdown properly with the team compiling a summary of steps taken (markdown) and code completed (python)\n",
    "    - Functions are provided for the team save files to disk regularly, especially these end of phase summaries\n",
    "    - Added benefit of being easy to inspect outputs and execute the phases whenever we want, picking up form where we left off\n",
    "- The instructions for the next phase are prepended with these summaries, consider them a briefing on work to date \n",
    "    - this summary approach saves tokens, hence costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "The model is GTP-4-Turbo (1106-Preview), with no fall back onto either GPT3.5 (because it  fails) or GPT4 (expensive, small context window). No fall back means we wait for GPT4 Turbo to be available, regardless rate limits and wait time. The greates fear is hitting the context window limit because AutoGen does not handle this gracefully, the entire conversation is lost, costing money and time.\n",
    "\n",
    "PRICE:\n",
    "GPT-4-Turbo is not cheap. Executing the code for all phases in this project will cost around USD 50 !\n",
    "It is tempting to allow the team full access to the previous phases' conversavtion. This is done when configuring user_proxy.initiate_chat() by assigning clear_history = True. The full conversation is then prepended to all chat messages. However, this soon uses the full 128k context window and becomes extravagantly expensive. If you leave the room and allow the team to chat, then they will happily run up a tab over USD 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oliver/Documents/LangChain/ProductDevelopment/AutoGen\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Working directory and environment keys\n",
    "os.chdir(\"/home/oliver/Documents/LangChain/ProductDevelopment/AutoGen\")\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"model\":\"gpt-4-1106-preview\",\"api_key\":\"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\"},{\"model\":\"gpt-3.5-turbo-1106\",\"api_key\":\"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\"} ]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# read local .env file\n",
    "_ = load_dotenv(find_dotenv(usecwd=True)) \n",
    "\n",
    "oai_config_value = os.environ.get('OAI_CONFIG_LIST')\n",
    "print(oai_config_value)\n",
    "\n",
    "#del os.environ['OAI_CONFIG_LIST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "# get config, which is in the OAI_CONFIG_LIST.json file\n",
    "config_list= autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": {\"gpt-4-1106-preview\"} # Only use GPT4-Turbo, exclude 3.5. {\"gpt-3.5-turbo-1106\"} \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "The team will be assigned functions for convenience, most importantly functions for reading and writing to disk.\n",
    "They are capable of writing all the functios they need, but for repeated tasks that can be tiresome and a waste fo tokens.\n",
    "\n",
    "See guide for functions in autogen at:\n",
    "\n",
    "https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_from_disk(folder, file_name):\n",
    "    \"\"\"\n",
    "    This function loads a specified file from a given folder, checks if it's a text-based file and not too long, \n",
    "    and then prints its content to the screen.\n",
    "\n",
    "    CANNOT be used for assigning a variable to the content of the file.\n",
    "\n",
    "    :param folder: The folder, relative to cwd, containing the file.\n",
    "    :param file_name: The name of the file to be loaded and printed.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import mimetypes\n",
    "\n",
    "    folder_path = os.path.join(cwd, folder)\n",
    "\n",
    "    # Construct the full path of the file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        reply = f\"File {file_name} does not exist in the folder {folder_path}.\" \n",
    "        #print(reply)\n",
    "        return reply\n",
    "\n",
    "    # Check if the file is text-based\n",
    "    file_type, _ = mimetypes.guess_type(file_path)\n",
    "    if not file_type or not file_type.startswith('text'):\n",
    "        reply = f\"The file {file_name} is not a text-based file.\"\n",
    "        #print(reply)\n",
    "        return reply\n",
    "\n",
    "    # Open and read the file, then print its contents\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            reply = file.read(1000000) # 1000000 char limit (i.e. no limit)\n",
    "            print(reply)\n",
    "\n",
    "            # Check if the file content is longer than the display_length\n",
    "            if file.read(1):  # Read one more character to see if there is more content\n",
    "                reply = reply + \"\\n[Content truncated due to length limit]\"\n",
    "                print(\"\\n[Content truncated due to length limit]\")\n",
    "    except Exception as e:\n",
    "        reply = f\"An error occurred while reading the file: {e}\"\n",
    "        #print(reply)\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file_from_disk_schema = {\n",
    "\n",
    "    \"name\": \"read_file_from_disk\",\n",
    "    \"description\": \"Loads a specified file from a given folder, checks if it's a text-based file and not too long, and then prints its content to the screen. CANNOT be used for assigning a variable to the content of the file.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"folder\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The folder, relative to current working directory, containing the file.\"\n",
    "            },\n",
    "            \"file_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the file to be loaded and printed.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"folder\", \"file_name\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_file_from_disk(folder, file_name):\n",
    "    \"\"\"\n",
    "    This function loads a specified Parquet file from a given folder and returns it for viewing.\n",
    "    CANNOT be used for assigning a variable to the dataset.\n",
    "\n",
    "    :param folder: The folder, relative to cwd, containing the file.\n",
    "    :param file_name: The name of the file to be loaded.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    # Assuming cwd is defined elsewhere or use os.getcwd() if it's the current working directory\n",
    "    folder_path = os.path.join(cwd, folder)\n",
    "\n",
    "    # Construct the full path of the file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        reply = f\"File {file_name} does not exist in the folder {folder_path}.\" \n",
    "        #print(reply)\n",
    "        return reply\n",
    "\n",
    "    # Read the Parquet file and print its contents\n",
    "    try:\n",
    "        reply = pd.read_parquet(file_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        reply = f\"An error occurred while reading the file: {e}\"\n",
    "\n",
    "    return reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_parquet_file_from_disk_schema = {\n",
    "\n",
    "    \"name\": \"read_parquet_file_from_disk\",\n",
    "    \"description\": \"Loads a specified Parquet file from a given folder and returns content for use in pandas. CANNOT be used for assigning a variable to the dataset.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"folder\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The folder, relative to the current working directory, containing the file.\"\n",
    "            },\n",
    "            \"file_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the Parquet file to be loaded.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"folder\", \"file_name\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pandas_data_to_parquet(df, folder, file_name):\n",
    "    \"\"\"\n",
    "    This function saves a given Pandas DataFrame or a dictionary to a Parquet file in the specified folder.\n",
    "\n",
    "    :param df: Pandas DataFrame or dictionary to be saved.\n",
    "    :param folder: The folder, relative to the current working directory, where the file will be saved.\n",
    "    :param file_name: The name of the Parquet file to be created.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    # Check if df is a dictionary and convert it to a DataFrame if it is\n",
    "    if isinstance(df, dict):\n",
    "        df = pd.DataFrame.from_dict(df)\n",
    "\n",
    "    # Construct the folder path\n",
    "    folder_path = os.path.join(os.getcwd(), folder)\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Construct the full path of the file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Write the DataFrame to a Parquet file\n",
    "    try:\n",
    "        df.to_parquet(file_path)\n",
    "        reply = f\"DataFrame successfully written to {file_path}\"\n",
    "    except Exception as e:\n",
    "        reply = f\"An error occurred while writing the DataFrame to file: {e}\"\n",
    "\n",
    "    return reply\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pandas_data_to_parquet_schema = {\n",
    "\n",
    "    \"name\": \"write_pandas_data_to_parquet\",\n",
    "    \"description\": \"Saves a given Pandas DataFrame to a Parquet file in the specified folder. Can only be used with Pandas.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"df\": {\n",
    "                \"type\": \"object\",\n",
    "                \"description\": \"Pandas DataFrame to be saved.\"\n",
    "            },\n",
    "            \"folder\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The folder, relative to the current working directory, where the file will be saved.\"\n",
    "            },\n",
    "            \"file_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the Parquet file to be created.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"df\", \"folder\", \"file_name\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text_format_file_to_disk(folder, file_name, content):\n",
    "    \"\"\"\n",
    "    This function writes markdown or python content to a file within a specified folder.\n",
    "    \n",
    "    :param folder_path: The path to the folder where the file will be written.\n",
    "    :param file_name: The name of the file to be written.\n",
    "    :param content: The content to write to the file.\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    folder_path = os.path.join(cwd, folder)\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Construct the full path of the file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Write content to the file\n",
    "    try:\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(content)\n",
    "            reply = f\"Content written to {file_path} successfully.\"\n",
    "            #print(reply)\n",
    "    except Exception as e:\n",
    "        reply = f\"An error occurred while writing to the file: {e}\"\n",
    "        #print(reply)\n",
    "\n",
    "    return reply\n",
    "\n",
    "# Example usage\n",
    "# write_text_format_file_to_disk(\"/path/to/folder\", \"example.txt\", \"Hello, World!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_text_format_file_to_disk_schema = {\n",
    "    \n",
    "    \"name\": \"write_text_format_file_to_disk\",\n",
    "    \"description\": \"Writes markdown or python content to a file within a specified folder.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"folder\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The path to the folder where the file will be written.\"\n",
    "            },\n",
    "            \"file_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the file to be written.\"\n",
    "            },\n",
    "            \"content\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The content to write to the file.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"folder\", \"file_name\", \"content\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_python_files_in_folder(folder):\n",
    "    \"\"\"\n",
    "    This function loads each Python file (.py) from a given folder, concatenates them with the file name \n",
    "    and an underline at the head of each file, prints the concatenated file to the screen, \n",
    "    and returns the concatenated content.\n",
    "\n",
    "    :param folder_path: The path to the folder containing the Python files.\n",
    "    :return: The concatenated content of all Python files in the folder.\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    folder_path = os.path.join(cwd, folder)\n",
    "\n",
    "    reply = \"\"\n",
    "\n",
    "    # Iterate over all files in the given folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".py\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Add file name and underline at the head of each file's content\n",
    "            reply += f\"\\n # {file_name}\\n\" + \"#\"+\"-\" * len(file_name) + \"\\n\"\n",
    "\n",
    "            # Open and read the file\n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    reply += file.read() + \"\\n\"\n",
    "            except Exception as e:\n",
    "                error = f\"An error occurred while reading the file {file_name}: {e}\"\n",
    "                reply += error\n",
    "  \n",
    "    # Print the concatenated content\n",
    "    # print(reply)\n",
    "\n",
    "    return reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_all_python_files_in_folder_schema = {\n",
    "    \n",
    "    \"name\": \"read_all_python_files_in_folder\",\n",
    "    \"description\": \"Loads each Python file (.py) from a given folder, concatenates them with the file name and an underline at the head of each file, prints the concatenated file to the screen, and returns the concatenated content.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"folder\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The path to the folder containing the Python files.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"folder\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a function which will read all progress to date into the prompt at the start of each phase\n",
    "The team are NOT assigned this function, we require it to brief the team on what has ahppened in previous project phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def concatenate_files(folder, file_extensions):\n",
    "    \"\"\"\n",
    "    Concatenates files of specified types in a given folder into a single Markdown string.\n",
    "    Non-Markdown contents are quoted with triple backticks.\n",
    "\n",
    "    Args:\n",
    "    folder_path (str): The path to the folder containing the files.\n",
    "    file_extensions (list): A list of file extensions to include (e.g., ['md', 'py']).\n",
    "\n",
    "    Returns:\n",
    "    str: A Markdown string containing the contents of all specified files.\n",
    "    \"\"\"\n",
    "    file_contents = []\n",
    "\n",
    "    folder_path = os.path.join(cwd, folder)\n",
    "\n",
    "    for ext in file_extensions:\n",
    "        # Find all files in the folder that match the current extension\n",
    "        files = glob.glob(os.path.join(folder_path, f'*.{ext}'))\n",
    "\n",
    "        for file in files:\n",
    "            file_name = os.path.basename(file)\n",
    "            file_contents.append(f'# {file_name}\\n')  # Add the file name as a header\n",
    "\n",
    "            with open(file, 'r') as f:\n",
    "                content = f.read()\n",
    "\n",
    "                # If the file is not a Markdown file, enclose its content in triple backticks\n",
    "                if ext != 'md':\n",
    "                    file_contents.append(f'```\\n{content}\\n```')\n",
    "                else:\n",
    "                    file_contents.append(content)\n",
    "\n",
    "            file_contents.append('\\n')  # Add an extra newline for separation\n",
    "\n",
    "    return '\\n'.join(file_contents)\n",
    "\n",
    "# Example usage\n",
    "# folder_path = 'path/to/your/folder'\n",
    "# file_extensions = ['md', 'py']\n",
    "# all_contents = concatenate_files(folder_path, file_extensions)\n",
    "# print(all_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_config = {\n",
    "    \"seed\"            : 42,  # change the seed for different trials\n",
    "    \"temperature\"     : 0,   # 0 uses most likely token every time, highly repeatable. 1 is more creative.\n",
    "    \"config_list\"     : config_list,\n",
    "    \"request_timeout\" : 5*60,\n",
    "}\n",
    "\n",
    "# Create variations with access to functions\n",
    "gpt_config_allfn = gpt_config.copy()\n",
    "gpt_config_allfn['functions']=[ read_file_from_disk_schema,\n",
    "                                read_parquet_file_from_disk_schema,\n",
    "                                write_pandas_data_to_parquet_schema,\n",
    "                                write_text_format_file_to_disk_schema,\n",
    "                                read_all_python_files_in_folder_schema]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Microsoft TDSP (Team Data Science Process)\n",
    "\n",
    "Based on Microsoft's Team Data Science Process (TDSP)\n",
    "- https://learn.microsoft.com/en-us/azure/architecture/data-science-process/overview\n",
    "\n",
    "Phase descriptions at https://learn.microsoft.com/en-us/azure/architecture/data-science-process/lifecycle-data\n",
    "- Template at: https://github.com/Azure/Azure-TDSP-ProjectTemplate\n",
    "\n",
    "This process is only used by one of the experiments, whereas the baseline experiment has no process imposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Microsoft_TDSP = []\n",
    "\n",
    "Microsoft_TDSP.append(\n",
    "\"\"\"\n",
    "Phase 0. Business Understanding \n",
    "============================\n",
    "You must operate within the confines of this tasks and this phase. Do not plan or execute other project phases until instructed.\n",
    "\n",
    "TASK:\n",
    "    Present a Project Charter report (No code to be written in this phase): \n",
    "    - Summary of business objectives\n",
    "    - Scope (whats in and whats excluded)\n",
    "    - Metrics (SMART)\n",
    "    - Approach (Proof of Concept OR Proof of Value OR Full solution)\n",
    "    Present the Project Charter to the Admin in Markdown format. \n",
    "    Following approval from Admin, save the following files to the '\"\"\"+cwd+\"\"\"/Phase0' folder:\n",
    "    a) Use the write_text_format_file_to_disk function to save this Project Charter in markdown format to '\"\"\"+cwd+\"\"\"/Phase0/Project_Charter.md' to disk\n",
    "    b) Use the write_text_format_file_to_disk function to save this UML in plantUML format to '\"\"\"+cwd+\"\"\"/Phase0/UML.puml'\n",
    "\n",
    "    At the end of the task prepare a detailed summary:\n",
    "\n",
    "    a) the sequence of decisions and steps taken during the group chat, including their outcome\n",
    "    b) a summary of information which would be useful to a future team needing to advance the project to the next phase, \n",
    "        - location of data and code files\n",
    "        - anticipated concerns \n",
    "        - problems encountered and how they were resolved (or not resolved)\n",
    "    c) The folder and file location of the cleaned data you have been working with\n",
    "    Use the write_text_format_file_to_disk function to save this phase summary in markdown format to '\"\"\"+cwd+\"\"\"/Phase0/Phase_Summary.md'\n",
    "    \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per the phase decription at:\n",
    "# https://learn.microsoft.com/en-us/azure/architecture/data-science-process/lifecycle-data\n",
    "Microsoft_TDSP.append(\n",
    "\"\"\"\n",
    "# Phase 1. Data Acquisition and Understanding \n",
    "==============================================\n",
    "You must operate within the confines of this tasks and this phase. Do not plan or execute other project phases until instructed.\n",
    "\n",
    "# TASK 1: Present and enact an iterative plan, whose motivation is the Project Charter, to addresses the below concerns: \n",
    "\n",
    "## Clean the data\n",
    "\n",
    "    - Write code to read the source data and assign it to a variable for inspection\n",
    "    - become acquainted with each data type present\n",
    "    - Analyse for cleanliness and completeness\n",
    "    - Create a new cleaned version of the data\n",
    "    - save the cleaned data to this folder '\"\"\"+cwd+\"\"\"/Phase1'\n",
    "\n",
    "## Explore the data\n",
    "        \n",
    "    - Remind yourself of the business objective\n",
    "    - Characterise each data type in the source data\n",
    "    - Is the solution to the business objective already in the data? Do not assume analysis is necessary.\n",
    "    - Assuming algorithms will be necessary, what common data preprocessing would be required before algorithms can be applied to the data?\n",
    "    - Code that preprocessing in python and execute it\n",
    "    - Save the resulting data to this folder '\"\"\"+cwd+\"\"\"/Phase1'\n",
    "\n",
    "# TASK 2: Phase Close Down\n",
    "\n",
    "    Present a Data Summary report in Markdown format, refer to code and data used in the analysis.\n",
    "    Following approval from Admin, save the following files to the '\"\"\"+cwd+\"\"\"/Phase1' folder:\n",
    "    a) save the Data Summary in markdown format as 'Data_Summary.md' to disk\n",
    "    b) save processed data in parquet format as 'Processed_Data.parquet'.to disk\n",
    "\n",
    "    At the end of the task prepare a detailed summary:\n",
    "\n",
    "    a) the sequence of decisions and steps taken during the group chat, including their outcome\n",
    "    b) a summary of information which would be useful to a future team needing to advance the project to the next phase, \n",
    "        - location of data and code files\n",
    "        - anticipated concerns \n",
    "        - problems encountered and how they were resolved (or not resolved)\n",
    "    c) The folder and file location of the cleaned data you have been working with\n",
    "    Save this summary in markdown format as '\"\"\"+cwd+\"\"\"/Phase1/Phase_Summary.md' to disk.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per the phase decription at:\n",
    "# https://learn.microsoft.com/en-us/azure/architecture/data-science-process/lifecycle-modeling\n",
    "Microsoft_TDSP.append(\n",
    "\"\"\"\n",
    "Phase 2. Modelling\n",
    "============================\n",
    "You must operate within the confines of these tasks and this phase. Do not plan or execute other project phases until instructed.\n",
    "\n",
    "# TASK 1: Present and enact an iterative plan, whose context is the Project Charter and Data Summary, to address the below concerns.\n",
    "\n",
    "## GOALS\n",
    "- Determine the optimal data features for the machine-learning model.\n",
    "- Create an informative machine-learning model that predicts the target most accurately.\n",
    "- Create a machine-learning model that's suitable for production.\n",
    "\n",
    "## FORMULATE APPROACH\n",
    "\n",
    "Hypothesise a solution to the client's business problem at a high level, then expand into the details. In order to do this:\n",
    "- Remind yourself of the business objective\n",
    "- Write code to load the data from file into a variable. Execute that code and inspect the data to become acquainted with each data type present\n",
    "- Stand back from the problem, take a deep breath and think of some similar problems and how they were approached\n",
    "- Write down one of those approaches and the main steps that were involved to wrangle data, process it with algorithms and export processed data\n",
    "\n",
    "### EXECUTE APPROACH\n",
    "\n",
    "- Begin the process of iteratively exploring the data and possible algorithms via Jupyter Notebook cells\n",
    "- Ensure you write code in sufficiently small cells that the execution of that cell can guide your next step. \n",
    "- DO NOT try to solve the entire problem in one cell.\n",
    "- Do not visualise data, your environment cannot display charts\n",
    "- Be agile in your approach: after executing each cell, reflect on the results and let them guide your next steps. Propose code tailored to the evolving understanding of the dataset and the business objectives. \n",
    "- Save the approach steps into a markdown file of the plan, in folder 'Phase2', filename='Approach1.md'\n",
    "- Save your notebook code in folder 'Phase2' filename='hypothesis1.py'\n",
    "- Save any data created during the process in folder 'Phase2' filename='hypothesis1_data_xx.parquet', where xx is a sequential number starting from 01.\n",
    "- Record a summary of the process and evaluate its success. Append these notes to Approach1.md in the 'Phase2' folder\n",
    "\n",
    "## APPROACHES 2 & 3\n",
    "\n",
    "- Formulate and execute alternative approaches, if requested.\n",
    "\n",
    "# TASK 2: Phase Close Down\n",
    "\n",
    "Summarise findings in a Modelling report in Markdown format, refer to code and data used in the analysis and the folder/file location of those data files.\n",
    "\n",
    "    Use the write_text_format_file_to_disk function to save the following files to this folder 'Phase2':\n",
    "    a) the Modelling report in markdown format as 'Modelling.md'\n",
    "    b) the processed data in parquet format, for example 'Processed_Data.parquet'\n",
    "    c) the python code to 'Modelling.py'\n",
    "    d) any charts or plots to files in jpg format\n",
    "    Then execute this code to save files.\n",
    "\n",
    "    It is essential to save the code file. To test this, the team must write and execute code to confirm the code files can be opened from their save location.\n",
    "    At the end of the task prepare a detailed summary:\n",
    "\n",
    "    a) the sequence of decisions and steps taken during the group chat, including their outcome\n",
    "    b) a summary of information which would be useful to a future team needing to advance the project to the next phase, \n",
    "        - location of data and code files\n",
    "        - anticipated concerns \n",
    "        - problems encountered and how they were resolved (or not resolved)\n",
    "    c) The folder and file location of the cleaned data you have been working with\n",
    "    Use the write_text_format_file_to_disk function to save this phase summary to folder 'Phase2', filename='Phase_Summary.md'. Then execute this code\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Microsoft_TDSP.append(\n",
    "\"\"\"\n",
    "Phase 3. Model Evaluation & Enhancement\n",
    "===================================================\n",
    "You must operate within the confines of these tasks and this phase. Do not plan or execute other project phases until instructed.\n",
    "\n",
    "# TASK 1: Evaluate The Model\n",
    "\n",
    "- Extract the code for the final model resulting from Phase 2.\n",
    "- Execute the Model from Phase 2\n",
    "- Review the results presented by the Executor. Critique those results, are they likely to be effective for the business objective ? \n",
    "- Make recommendations for how the results could be improved, with the business objectives in mind\n",
    "- Develop code for a more effective mode\n",
    "- Finalise an improved model\n",
    "\n",
    "# TASK 2: Phase Close Down\n",
    "\n",
    "Summarise findings in a Evaluation report in Markdown format, refer to code and data used in the analysis and the folder/file location of those data files.\n",
    "\n",
    "    Use the write_text_format_file_to_disk function to save the following files to this folder 'Phase3':\n",
    "    a) the Model Evaluation report in markdown format as 'Modelling.md'\n",
    "    b) the processed data in parquet format, for example 'Processed_Data.parquet'\n",
    "    c) the improved model's python code to 'Modelling.py'\n",
    "    d) any charts or plots to files in jpg format\n",
    "    Then execute this code to save files.\n",
    "\n",
    "    It is essential to save the code file. To test this, the team must write and execute code to confirm the code files can be opened from their save location.\n",
    "    At the end of the task prepare a detailed summary:\n",
    "\n",
    "    a) the sequence of decisions and steps taken during the group chat, including their outcome\n",
    "    b) a summary of information which would be useful to a future team needing to advance the project to the next phase, \n",
    "        - location of data and code files\n",
    "        - anticipated concerns \n",
    "        - problems encountered and how they were resolved (or not resolved)\n",
    "    c) The folder and file location of the cleaned data you have been working with\n",
    "    Use the write_text_format_file_to_disk function to save this phase summary to folder 'Phase3', filename='Phase_Summary.md'. Then execute this code\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The equivalent phase in the formal TDSP is 'Deployment', however, we diverge and describe 'Productionisation'\n",
    "Microsoft_TDSP.append(\n",
    "\"\"\"\n",
    "Phase 4. Productionisation \n",
    "============================\n",
    "You must operate within the confines of these tasks and this phase. Do not plan or execute other project phases until instructed.\n",
    "\n",
    "# TASK 1: Present and enact an iterative plan, whose context is the Project Charter and Modelling Report, to address the below concerns.\n",
    "\n",
    "## Code enhancements\n",
    "\n",
    "    ### Write a critique of the modelling code\n",
    "    - Implement refactoring, simplification, if available\n",
    "    - Implement performance enhancements, if available\n",
    "    - Add explanatory code notes, wherever helpful\n",
    "    - Add type hints, wherever helpful\n",
    "\n",
    "    ### FOR EACH iteration IN RANGE(0,2):\n",
    "\n",
    "    Critique the code\n",
    "    - Is the object model sensible and extensible?\n",
    "    - Are the tests useful and reasonably complete?\n",
    "    - Does the code behave as expected?\n",
    "\n",
    "    Apply Improvements:\n",
    "    \n",
    "        #### Object Oriented Code\n",
    "        - Arrange code into an object oriented approach\n",
    "        - Make use of multiple classes\n",
    "\n",
    "        #### Implement Test Code (with pytest)\n",
    "        - Add unit test code \n",
    "        - Add integration test code\n",
    "\n",
    "        #### Test the Enhanced code\n",
    "        - Confirm model behaves as expected\n",
    "        - Confirm test code behaves as expected\n",
    "\n",
    "# TASK 2: Phase Close Down\n",
    "\n",
    "    Following approval from Admin, use the write_text_format_file_to_disk function to save the following files to the 'Phase4' folder:\n",
    "    b) any processed data in parquet format, for example 'Processed_Data.parquet'\n",
    "    c) any python code to 'Productised.py'\n",
    "    d) any charts or plots to files in jpg format\n",
    "\n",
    "    It is essential to save the code file. To test this, the team must write and execute code to confirm the code files can be opened from their save location.\n",
    "    At the end of the task prepare a detailed summary:\n",
    "    \n",
    "    a) the sequence of decisions and steps taken during the group chat, including their outcome\n",
    "    b) a summary of information which would be useful to a future team needing to advance the project to the next phase, \n",
    "        - location of data and code files\n",
    "        - anticipated concerns \n",
    "        - problems encountered and how they were resolved (or not resolved)\n",
    "    c) The folder and file location of the cleaned data you have been working with\n",
    "    use the write_text_format_file_to_disk function to save the phase summary in markdown format in the 'Phase4' fodler as 'Phase_Summary.md'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Microsoft_TDSP.append(\n",
    "\"\"\"\n",
    "Phase 5. Acceptance\n",
    "============================\n",
    "You must operate within the confines of this tasks and this phase. Do not plan or execute other project phases until instructed.\n",
    "\n",
    "TASK:\n",
    "\n",
    "    Document the data pipeline in either markdown or plantUML\n",
    "    Document the model, object model in plantUML (sequence diagram, entity diagram, etc), and limits of applicability of the approach, eg on accuracy.\n",
    "    Summarise the work and lessons learnt\n",
    "    Following approval from Admin, use the write_text_format_file_to_disk function to save the following files to the '\"\"\"+cwd+\"\"\"/Phase5' folder:\n",
    "    a) save the Final Summary report in Markdown format to 'Final_Summary.md'\n",
    "    b) save text documentation in markdown format\n",
    "    c) save UML in plantUML format\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the team\n",
    "\n",
    "Assitants (LLM)\n",
    "- Engineer\n",
    "- Data scientist\n",
    "- Planner\n",
    "- Critic\n",
    "\n",
    "User Proxies (Local PC or User)\n",
    "- Executor (Code Execution)\n",
    "- Admin (Human)\n",
    "\n",
    "Arrangement\n",
    "- One 'groupchat'\n",
    "- Managed by a 'Manager'\n",
    "- Human in the loop as 'Admin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assistants ###\n",
    "\n",
    "# Assistant agent is designed to solve a task with LLM, it is a subclass of ConversableAgent\n",
    "# `human_input_mode` is default to \"NEVER\"\n",
    "# `code_execution_config` is default to False.\n",
    "# This agent doesn't execute code by default, and expects the user to execute the code.\n",
    "\n",
    "scientist = autogen.AssistantAgent(\n",
    "    name=\"DataScientist\",\n",
    "    llm_config=gpt_config_allfn,\n",
    "    system_message=\"\"\"Data Scientist. You follow an approved plan, iteratively.\n",
    "\n",
    "    You open and inspect data then suggest how it may need to be cleaned or arranged for analysis. Pay particular attention to each data type presented to you and its potential to assist with the business objective.\n",
    "    You subsequently step back to consider appropriate algorithms, you are an advocate of agile iterative approaches, so are prepared to propose and investigate multiple algorithms in the hunt for the optimal approach.\n",
    "\n",
    "    ALWAYS propose python code to the Critic for review, activiely name the critic in your code proposal. Wrap ALL proposed code in three tildas \"~~~\" at start and end.\n",
    "    The Critic will make suggestions about your proposed code. You will enhance your code accordingly and present the enhanced code for execution. \n",
    "    ONLY AFTER review by the critic shuld you present enhanced code, i.e. code now ready for execution. This MUST be wrapped in a code block denoted by \"```\". \n",
    "        \n",
    "    Your code must be designed for iterative work in a Jupyter notebook. \n",
    "    But NEVER present your code in json format EXCEPT when using a function made available to you for reading and writing files. NB: You cannot import any package called 'function' or 'functions'.\n",
    "    If you wish to assign a variable to data from file then you must write code to load the data, eg via pandas, and assign it to a variable.\n",
    "    \n",
    "    This is a notebook, the intent is that the team reviews the output from each code block before deciding on what steps to take next. So keep each block short. \n",
    "    The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
    "    Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
    "    If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. \n",
    "    If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "    If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line.\n",
    "\n",
    "    Do not show ANY appreciation in your responses.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "agilePM = autogen.AssistantAgent(\n",
    "    name=\"AgileProjectManager\",\n",
    "    llm_config=gpt_config,\n",
    "    system_message=\"\"\"Agile Project Manager. Suggest a high level plan for the current phase of the project, which is given to you. Do not plan other phases.\n",
    "    Revise the plan based on feedback from admin and critic, until admin approval.\n",
    "    The plan may involve a data scientist who writes code and yourself to revise the plan iteratiuvely, as per agile principles.\n",
    "    The data scientist can read and write files for you.\n",
    "    Do not show ANY appreciation in your responses.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "critic = autogen.AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    llm_config=gpt_config,\n",
    "    system_message=\"\"\"Critic. \n",
    "\n",
    "    As the Critic, your role is to evaluate and provide constructive feedback on proposals for project plans and proposed code. \n",
    "    Your critiques should focus on ensuring that the plans and code align with best practices for agile and iterative development, particularly within the Jupyter notebook format.\n",
    "    You must also redirect the conversation away from any team member who repeatedly posts blank comments in the group chat.\n",
    "\n",
    "    # ALWAYS Review Plans Proposed by the Team Members\n",
    "\n",
    "    Assess the feasibility, clarity, and practicality of the proposed project plans.\n",
    "    Suggest improvements or alternatives that enhance agility and flexibility.\n",
    "    Ensure the plans are not over prescriptive, thus support iterative development and team collaboration.\n",
    "    Cease critiques after the plan is approved by the Admin.\n",
    "\n",
    "    # ALWAYS Review Code Proposed by Team Members\n",
    "\n",
    "    Proposed code is wrapped in three tildas \"~~~\", critique such code whenever it appears in the group chat. Focus on its suitability for a Jupyter notebook.\n",
    "    Critique code only once, do not repeatedly comment on the same piece of code.\n",
    "    Never critique code in a formal code block, which is wrapped with this marker '```' .\n",
    "    This means, check for common issues, such as trying to achieve too many steps in one notebook cell, thus negating the advantages of iterative development.\n",
    "    Offer specific feedback on how to split up or improve the code chunk.\n",
    "    After providing your critique, prompt the team member who propsoed the code to present revised, smaller, or improved chunk of code suitable for execution in a Jupyter notebook. \n",
    "    This revision should be done independently, without further input from you, the Critic.\n",
    "\n",
    "    # ALWAYS Review Reponses from the Executor Which are Not Errors\n",
    "\n",
    "    Critique the progress being made, is the code returning desirable results? \n",
    "    Interpret the result. Having done so, what do the results tell us about the effectiveness of your work?\n",
    "\n",
    "    Remember, your goal is to foster a productive, agile environment where iterative development is emphasized. \n",
    "    Your feedback should be constructive, aiming to guide the team members towards more effective and efficient work practices.\n",
    "    Do not show ANY appreciation in your responses.\n",
    "    You NEVER write code\n",
    "    \"\"\",\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER AGENTS ###\n",
    "\n",
    "# User agents send messages to assistants\n",
    "# UserProxyAgent is a subclass of ConversableAgent \n",
    "# `human_input_mode` is set to ALWAYS by default, unless overridden. We override it for the Executor, see below\n",
    "# `llm_config` is set to False.They are humans or environments, not LLM.\n",
    "# Code execution is enabled by default. LLM-based auto reply is disabled by default.\n",
    "# User Agents have 'function maps' to use prepared functions\n",
    "# User Agents have code execution configs to setup the coding environment they execute code in\n",
    "# To modify auto reply, register a method with [`register_reply`](conversable_agent#register_reply).\n",
    "# To modify the way to get human input, override `get_human_input` method.\n",
    "# To modify the way to execute code blocks, single code block, or function call, override `execute_code_blocks`, `run_code`, and `execute_function` methods respectively.\n",
    "\n",
    "# Proxy to execute code\n",
    "\n",
    "executor = autogen.UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Executor. Execute the code written by the DataScientist and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"last_n_messages\": 3, \n",
    "                           \"work_dir\"       : \"paper\",        \n",
    "                           \"use_docker\"     : False,  # set to True or image name like \"python:3\" to use docker\n",
    "                           },\n",
    "    # only instances of user-proxy have a function_map\n",
    "    function_map = {\"read_file_from_disk\"                  : read_file_from_disk,\n",
    "                    \"read_parquet_file_from_disk\"          : read_parquet_file_from_disk,\n",
    "                    \"write_pandas_data_to_parquet\"         : write_pandas_data_to_parquet,\n",
    "                    \"write_text_format_file_to_disk\"       : write_text_format_file_to_disk,\n",
    "                    \"read_all_python_files_in_folder\"      : read_all_python_files_in_folder}\n",
    ")\n",
    "\n",
    "# Human in the loop\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"Admin\",\n",
    "   system_message=\"A human admin. Interact with the AgileProjectManager to discuss the plan and with the DataScientist to discuss approaches. Plan execution needs to be approved by this admin.\",\n",
    "   # user proxy is typically the only agent with termination message\n",
    "   is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "   code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,  # set to True or image name like \"python:3\" to use docker\n",
    "        \"last_n_messages\": 2,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ESTABLISH GROUP CHAT ##\n",
    "\n",
    "# A group chat class that contains the following data fields:\n",
    "#    - agents: a list of participating agents.\n",
    "#    - messages: a list of messages in the group chat.\n",
    "#    - admin_name: the name of the admin agent if there is one. Default is \"Admin\". KeyBoardInterrupt will make the admin agent take over.\n",
    "#    - func_call_filter: whether to enforce function call filter. Default is True. When set to True and when a message is a function call suggestion,\n",
    "#      the next speaker will be chosen from an agent which contains the corresponding function name in its `function_map`. That's the 'Executor' UserProxy in this example.\n",
    "\n",
    "groupchat = autogen.GroupChat(agents    = [user_proxy, scientist, critic, executor], \n",
    "                              admin_name= 'Admin', \n",
    "                              messages  = [], \n",
    "                              max_round = 50)\n",
    "\n",
    "# The chat is manage dby the chat_manager, which is a subclass of ConversableAgent like any other Agent\n",
    "# Therefore, it takes the llm_config\n",
    "# Thereafter, it manages who the next speaker should be\n",
    "\n",
    "manager   = autogen.GroupChatManager(groupchat  = groupchat, \n",
    "                                     llm_config = gpt_config_allfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "KickOff = \"\"\"The source data is at: '\"\"\" +cwd+\"\"\"/Data/data.xlsx' \n",
    "This is a list of applications which use AI. The client wants to understand and characterise the market, what sectors are likely to be over served and which are underserved.\n",
    "The client needs a summary diagram or table which can comfortably fit on one page of A4.\n",
    "\n",
    "The client is keen that :\n",
    "(a) no preconceptions are imposed on the data, select algorithms which avoid unevidenced assumptions\n",
    "(b) algorithm hyperparameters are optimised\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE - WITH ONE PHASE\n",
    "\n",
    "The first run is our basline. \n",
    "No project phases, we simply hand the problem, i.e. the Kick Off text, to the team and see how they perform.\n",
    "No further instructions are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_history = True\n",
    "silent        = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    recipient     = manager,\n",
    "    message       = KickOff,\n",
    "    clear_history = clear_history,\n",
    "    silent        = silent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH MULTIPLE PROJECT PHASES\n",
    "\n",
    "We now present the same problem to the same team, but ask them to complete only one phase.\n",
    "At the end of each phase they save their progress, which is presented as introductory material to the team on the next phase.\n",
    "\n",
    "Beware executing all these phases will cost approx USD60 with GPT-4-Turbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 0: Business Understanding\n",
    "\n",
    "phase0 = \"KICK OFF NOTES\\n\\n\" + \\\n",
    "        KickOff + \\\n",
    "        \"\\n\\n\" + \\\n",
    "        Microsoft_TDSP[0]\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    recipient     = manager,\n",
    "    message       = phase0,\n",
    "    clear_history = clear_history,\n",
    "    silent        = silent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Data Acquisition & Understanding\n",
    "\n",
    "catchup_phase0 = concatenate_files('Phase0', ['md'])\n",
    "\n",
    "message = \"KICK OFF NOTES\\n\\n\" + \\\n",
    "          KickOff + \"\\n\\n\" + \\\n",
    "          \"NOTES FROM THE BUSINESS UNDERSTANDING PHASE\\n\\n\" + \\\n",
    "          catchup_phase0 + \"\\n\\n\" + \\\n",
    "          \"YOUR INSTRUCTION FOR THIS PHASE\\n\\n\" + \\\n",
    "          Microsoft_TDSP[1]\n",
    "\n",
    "print(\"Commencing next phase\")\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    recipient     = manager,\n",
    "    message       = message,\n",
    "    clear_history = clear_history,\n",
    "    silent        = silent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Modelling\n",
    "\n",
    "catchup_phase0 = concatenate_files('Phase0', ['md'])\n",
    "catchup_phase1 = concatenate_files('Phase1', ['md', 'py'])\n",
    "\n",
    "message =   \"KICK OFF NOTES\\n\\n\" + \\\n",
    "            KickOff + \"\\n\\n\" + \\\n",
    "            \"NOTES FROM PHASE 0: Business Understanding: \\n\\n\" + \\\n",
    "            catchup_phase0 + \"\\n\\n\" +\\\n",
    "            \"NOTES FROM PHASE 1: Data Acquisition and Understanding: \\n\\n\" + \\\n",
    "            catchup_phase1 + \"\\n\\n\" +\\\n",
    "            \"YOUR INSTRUCTION FOR THIS PHASE\\n\\n\" + \\\n",
    "            Microsoft_TDSP[2]\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    recipient     = manager,\n",
    "    message       = message,\n",
    "    clear_history = clear_history,\n",
    "    silent        = silent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3: Model Evaluation\n",
    "\n",
    "catchup_phase0 = concatenate_files('Phase0', ['md'])\n",
    "catchup_phase2 = concatenate_files('Phase2', ['md', 'py'])\n",
    "\n",
    "message =   \"KICK OFF NOTES\\n\\n\" + \\\n",
    "            KickOff + \"\\n\\n\" + \\\n",
    "            \"NOTES FROM PHASE 0: Business Understanding: \\n\\n\" + \\\n",
    "            catchup_phase0 + \"\\n\\n\" +\\\n",
    "            \"NOTES FROM PHASE 2: Modelling: \\n\\n\" + \\\n",
    "            catchup_phase2 + \"\\n\\n\" +\\\n",
    "            \"YOUR INSTRUCTION FOR THIS PHASE\\n\\n\" + \\\n",
    "            Microsoft_TDSP[3]\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    recipient     = manager,\n",
    "    message       = message,\n",
    "    clear_history = clear_history,\n",
    "    silent        = silent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4: Productionisation\n",
    "\n",
    "catchup_phase0 = concatenate_files('Phase0', ['md'])\n",
    "catchup_phase3 = concatenate_files('Phase3', ['md', 'py'])\n",
    "\n",
    "message =   \"NOTES FROM PHASE 0: Business Understanding: \\n\\n\" + \\\n",
    "            catchup_phase0 + \"\\n\\n\" +\\\n",
    "            \"NOTES FROM PHASE 3: Model Evaluation: \\n\\n\" + \\\n",
    "            catchup_phase3 + \"\\n\\n\" +\\\n",
    "            \"YOUR INSTRUCTION FOR THIS PHASE\\n\\n\" + \\\n",
    "            Microsoft_TDSP[4]\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    recipient     = manager,\n",
    "    message       = message,\n",
    "    clear_history = clear_history,\n",
    "    silent        = silent   \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
